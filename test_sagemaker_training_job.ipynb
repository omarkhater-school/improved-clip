{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d80c6b3",
   "metadata": {},
   "source": [
    "## Test the main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2cb9fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args before running the pipeline: \n",
      "Namespace(data_path='D:/projects/improved-clip/src/datasets', ann_path='D:/projects/improved-clip/src/datasets/clip_train', train_file='D:/projects/improved-clip/src/datasets/clip_train\\\\cc3m_train_subset.json', train_image_root='D:/projects/improved-clip/src/datasets\\\\cc3m_subset_100k', bert_config='configs/config_bert.json', image_encoder='resnet50', text_encoder='distilbert-base-uncased', image_res=256, vision_width=768, embed_dim=256, optimizer='fusedadam', sched='cosine', lr=0.0002, lr_temp_net=1e-06, wd_temp_net=0.001, min_lr=1e-06, warmup=True, warmup_lr=1e-05, weight_decay=0.02, decay_rate=1, epochs=1, warmup_epochs=5, cooldown_epochs=0, use_amp=True, init_model=True, batch_size_train=128, batch_size_test=128, k_test=256, evaluate=True, val_frequency=5, checkpoint='', device='cuda', seed=42, world_size=1, dist_url='env://', distributed=False, no_distributed=False, step_size_per_epoch=100, print_freq_per_epoch=100, resume_learning=False, output_dir='D:/projects/improved-clip/test_output', loss_function='isogclr_new', vicreg_sim_coeff=25.0, vicreg_std_coeff=25.0, sogclr_gamma=0.8, rho_I=8.0, rho_T=8.0, eta_init=0.03, tau_init=0.01, beta_u=0.9, temp=0.01, learnable_temp=True, personalized_tau=True, max_norm=1.0, store_tau=True, isogclr_temp_net=True, alpha=1.0, train_frac=1.0, check_samples_tau=True, extract_data=True, zs_dataset='imagenet', zs_datafolder='D:/projects/improved-clip/src/datasets/imagenet/val', val_coco_file='D:/projects/improved-clip/src/datasets/clip_train\\\\coco_val.json', coco_image_root='D:/projects/improved-clip/src/datasets\\\\mscoco_val/mscoco_val2014_subset_5k')\n",
      "Args after manage path: \n",
      "Namespace(data_path='D:/projects/improved-clip/src/datasets', ann_path='D:/projects/improved-clip/src/datasets/clip_train', train_file='D:/projects/improved-clip/src/datasets/clip_train\\\\cc3m_train_subset.json', train_image_root='D:/projects/improved-clip/src/datasets\\\\cc3m_subset_100k', bert_config='configs/config_bert.json', image_encoder='resnet50', text_encoder='distilbert-base-uncased', image_res=256, vision_width=768, embed_dim=256, optimizer='fusedadam', sched='cosine', lr=0.0002, lr_temp_net=1e-06, wd_temp_net=0.001, min_lr=1e-06, warmup=True, warmup_lr=1e-05, weight_decay=0.02, decay_rate=1, epochs=1, warmup_epochs=5, cooldown_epochs=0, use_amp=True, init_model=True, batch_size_train=128, batch_size_test=128, k_test=256, evaluate=True, val_frequency=5, checkpoint='', device='cuda', seed=42, world_size=1, dist_url='env://', distributed=False, no_distributed=False, step_size_per_epoch=100, print_freq_per_epoch=100, resume_learning=False, output_dir='D:/projects/improved-clip/src/datasets\\\\outputs', loss_function='isogclr_new', vicreg_sim_coeff=25.0, vicreg_std_coeff=25.0, sogclr_gamma=0.8, rho_I=8.0, rho_T=8.0, eta_init=0.03, tau_init=0.01, beta_u=0.9, temp=0.01, learnable_temp=True, personalized_tau=True, max_norm=1.0, store_tau=True, isogclr_temp_net=True, alpha=1.0, train_frac=1.0, check_samples_tau=True, extract_data=True, zs_dataset='imagenet', zs_datafolder='D:/projects/improved-clip/src/datasets/imagenet/val', val_coco_file='D:/projects/improved-clip/src/datasets/clip_train\\\\coco_val.json', coco_image_root='D:/projects/improved-clip/src/datasets\\\\mscoco_val/mscoco_val2014_subset_5k', gpu=0)\n",
      "***\n",
      "Creating retrieval dataset\n",
      "***\n",
      "len of train_dataset: 100000\n",
      "len of validation dataset: 5000\n",
      "***\n",
      "Creating model\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\projects\\improved-clip\\src\\improved-clip\\main.py\", line 231, in <module>\n",
      "    run_pipeline(args)\n",
      "  File \"d:\\projects\\improved-clip\\src\\improved-clip\\main.py\", line 47, in run_pipeline\n",
      "    model = CLIP(\n",
      "  File \"d:\\projects\\improved-clip\\src\\improved-clip\\models\\model_clip.py\", line 130, in __init__\n",
      "    self.criterion = iSogCLR_New_Loss(\n",
      "  File \"d:\\projects\\improved-clip\\src\\improved-clip\\models\\losses.py\", line 172, in __init__\n",
      "    self.s_I = torch.zeros(N).cuda()\n",
      "  File \"d:\\projects\\improved-clip\\src\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --data_path \"D:/projects/improved-clip/src/datasets\" \\\n",
    "    --ann_path \"D:/projects/improved-clip/src/datasets/clip_train\" \\\n",
    "    --zs_datafolder \"D:/projects/improved-clip/src/datasets/imagenet/val\" \\\n",
    "    --train_file cc3m_train_subset.json \\\n",
    "    --train_image_root cc3m_subset_100k \\\n",
    "    --output_dir \"D:/projects/improved-clip/test_output\" \\\n",
    "    --loss_function isogclr_new \\\n",
    "    --optimizer fusedadam \\\n",
    "    --tau_init 0.01 \\\n",
    "    --sogclr_gamma 0.8 \\\n",
    "    --eta_init 0.03 --sched cosine \\\n",
    "    --device cuda \\\n",
    "    --val_frequency 5 \\\n",
    "    --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05545dd5",
   "metadata": {},
   "source": [
    "## Test Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc07a27-e38b-4c6a-8b3a-0cddee7c9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_sagemaker.py \\\n",
    "    --entry_point main.py \\\n",
    "    --source_dir . \\\n",
    "    --instance_type ml.g5.4xlarge\\\n",
    "    --use_spot \\\n",
    "    --max_wait 36000 \\\n",
    "    --config_file ./config.json \\\n",
    "    --job_name \"Test-cloud-metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6b53b",
   "metadata": {},
   "source": [
    "## Test Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c21f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/24/24 04:06:10] INFO     Found credentials in shared    credentials.py:1278\n",
      "                             credentials file:                                 \n",
      "                             ~/.aws/credentials                                \n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Omar\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n",
      "[11/24/24 04:06:13] INFO     Found credentials in           credentials.py:1147\n",
      "                             environment variables.                            \n",
      "                    INFO     Found credentials in           credentials.py:1147\n",
      "                             environment variables.                            \n",
      "[11/24/24 04:06:17] WARNING  No finished training job found   estimator.py:1909\n",
      "                             associated with this estimator.                   \n",
      "                             Please make sure this estimator                   \n",
      "                             is only used for building                         \n",
      "                             workflow config                                   \n",
      "                    INFO     image_uri is not presented,      image_uris.py:674\n",
      "                             retrieving image_uri based on                     \n",
      "                             instance_type, framework etc.                     \n",
      "                    INFO     Creating hyperparameter tuning job session.py:3314\n",
      "                             with name:                                        \n",
      "                             improved-clip-phase2-241124-0406                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\improved-clip\\src\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python tuning.py \\\n",
    "    --entry_point main.py \\\n",
    "    --source_dir . \\\n",
    "    --instance_type ml.g5.4xlarge\\\n",
    "    --use_spot \\\n",
    "    --max_wait 36000 \\\n",
    "    --config_file ./config_phase2.json \\\n",
    "    --job_name \"improved-clip-phase2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe565e8-062e-4a00-9c36-2020006ccd06",
   "metadata": {},
   "source": [
    "ml.g5.4xlarge | 16 CPU | NVIDIA A10G 64GB Memory | 10 spot | $2.03\n",
    "ml.g4dn.4xlarge | 16 CPU | NVIDIA T4 64GB memory| 10 spot| $1.505\n",
    "ml.p3.2xlarge | 8 CPU | \tNVIDIA V100 61GB memory | 5 spot | $3.825\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
